---
title: "11-7-19 tree"
author: "Megan Beaudry"
date: "11/7/2019"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
Libraries
Load the libraries
```{r}
library('tidyr')
library('dplyr')
library('forcats')
library('ggplot2')
library('knitr')
library('caret')
library('doParallel')
library('rpart')
library('rpart.plot')
library('mda')
library('ranger')
library('e1071')
library('visdat')
```


Load the data

```{r}
clean_water_quality_data <- readRDS("../../data/processed_data/clean_water_quality_data.rds")
#if you get an error - this happens because you need to save the file first cause it refers to a relative path 
clean_data <- clean_water_quality_data
```

MOVE
Move the outcome variable to the first row
```{r reorder}
clean_data_2 <- clean_data[, c(4,1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24)]
```


SPLIT data
```{r split data}

library(caret)
library("tidyverse")
#this code does the data splitting. I still assume that your data is stored in the `d` object.
#uncomment to run
set.seed(123)
#extract observations/rows for training, assign to new variable. 
#Extracts 70% of the data into the trainset
trainset <- caret::createDataPartition(y = clean_data_2$A_butzleri_HSP60, p = 0.7, list = FALSE)
#subsets out the dataset
data_train = clean_data_2[trainset,] 
#do the same for the test set
data_test = clean_data_2[-trainset,] 
```

PARALLELIZATION
We want to use mutliple processors, which the code below will allow us to do.

We want to use mutliple processors, which the code below will allow us to do.
```{r parallel}
n_cores <- 4 #number of cores to use
cl <- makePSOCKcluster(n_cores)
registerDoParallel(cl) #comment out this line if you don't want parallel computing
```

Null Model
```{r null model}
mlr::measureACC("McCall_Lake", data_train$Pond)
```
Remove
we want to remove sampling site as this is to closely related to pong
```{r remove sampling slite}
data_train_2 <- data_train %>% dplyr::select(-Sampling_Site)
```


Lets start to build the tree now
```{r single fit}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "Pond"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_2)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_2)[-1], Accuracy = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_2)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_2)[n])) , data = data_train_2, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)
```

#want accuracy to be around .7
```{r Pond full fit}
set.seed(1111)
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit2 = caret::train(Pond  ~ ., data=data_train_2, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 20) 
print(fit2$results)
```
Time to build the final tree
```{r Pond final tree}
pond_tree <- prp(fit2$finalModel, extra = 1, type = 1)
ww=17.8/2.54; wh=ww;
dev.print(device=png,width=ww,height=wh,units="in",res=600,file="../../results/pond_tree.png")
```


```{r stop parallel}
# shut down the parallel computing cluster we created at the beginning of the analysis
stopCluster(cl)
```