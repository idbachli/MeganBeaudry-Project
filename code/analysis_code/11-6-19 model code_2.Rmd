---
title: "11-7-19 Model code"
author: "Megan Beaudry"
date: "11/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r}
library('tidyr')
library('dplyr')
library('forcats')
library('ggplot2')
library('knitr')
library('caret')
library('doParallel')
library('rpart')
library('rpart.plot')
library('mda')
library('ranger')
library('e1071')
library('visdat')
```

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
clean_water_quality_data <- readRDS("../../data/processed_data/clean_water_quality_data.rds")
#if you get an error - this happens because you need to save the file first cause it refers to a relative path 
clean_data <- clean_water_quality_data
```

MOVE
Move the outcome variable to the first row
```{r reorder}
clean_data_2 <- clean_data[, c(15,1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,17,18, 19)]
```


SPLIT data
```{r split data}

library(caret)
library("tidyverse")
#this code does the data splitting. I still assume that your data is stored in the `d` object.
#uncomment to run
set.seed(123)
#extract observations/rows for training, assign to new variable. 
#Extracts 70% of the data into the trainset
trainset <- caret::createDataPartition(y = clean_data_2$A_butzleri_HSP60, p = 0.7, list = FALSE)
#subsets out the dataset
data_train = clean_data_2[trainset,] 
#do the same for the test set
data_test = clean_data_2[-trainset,] 
```
NULL MODEL
```{r}
library(mlr) #We will jump between mlr and caret so call with :: at all times. 
mlr::measureACC("", data_train$A_butzleri_HSP60)
frequencies <- as.matrix(summary(data_train$A_butzleri_HSP60))
null_model <- max(frequencies)/length(data_train$A_butzleri_HSP60)
null_model
```
Null model accuracy is .013

## Single predictor models

Now let's consider single predictor models, i.e., we'll fit the outcome to each predictor one at a time to get an idea of the importance of individual predictors. Here, our model will be a tree. I'm actually not so sure if this makes a lot of sense since a "tree" with only one predictor seems a bit silly. But I guess we can try. It's similar to a 1-predictor GLM. 

```{r singlepredictor}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "A_butzleri_HSP60"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train)[-1], Accuracy = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train)[n])) , data = data_train, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)

#In order to get this code to work i had to specify the carett:: package
```


# Full model

Anyway, now let's fit a tree to the full model with all predictors. 

```{r fullfit}
set.seed(1111) #makes each code block reproducible
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit1 = caret::train(A_butzleri_HSP60  ~ ., data=data_train, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 10) 
print(fit1$results)

#again i added in caret to specify which package
```



```{r printfigure, message=FALSE}
library(rpart)
prp(fit1$finalModel, extra = 1, type = 1)

```



HF183
```{r}
data_train_2 <- clean_data[, c(8,1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19)]
library(mlr) #We will jump between mlr and caret so call with :: at all times. 
mlr::measureACC("", data_train$HF183)
frequencies <- as.matrix(summary(data_train$HF183))
null_model <- max(frequencies)/length(data_train$HF183)
null_model
```
```{r singlepredictor}


#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "HF183"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_2)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_2)[-1], Accuracy = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_2)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_2)[n])) , data = data_train_2, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)

#In order to get this code to work i had to specify the carett:: package
```


POND
```{r}
data_train_2 <- clean_data[, c(4,1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19)]
library(mlr) #We will jump between mlr and caret so call with :: at all times. 
mlr::measureACC("", data_train$Pond)
frequencies <- as.matrix(summary(data_train$Pond))
##null_model <- max(frequencies)/length(data_train$Week)
##null_model
```

```{r Single predictor POND}


#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "Pond"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_2)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_2)[-1], Accuracy = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_2)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_2)[n])) , data = data_train_2, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)

#In order to get this code to work i had to specify the carett:: package
```
```{r full-predictor tree acc}
set.seed(1111)
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit1 = caret::train(Pond  ~ ., data=data_train_2, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 10) 
print(fit1$results)
```


```{r}
prp(fit1$finalModel, extra = 1, type = 1)
```
splits along sampling site..ugh
```{r}
data_train_2 <- data_train_2 %>% dplyr::select(-Sampling_Site)
```

Model again
```{r}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "Pond"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_2)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_2)[-1], Accuracy = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_2)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit2 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_2)[n])) , data = data_train_2, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)
```

```{r full fit pond}
set.seed(1111)
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit2 = caret::train(Pond  ~ ., data=data_train_2, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 20) 
print(fit2$results)
```

```{r}
prp(fit2$finalModel, extra = 1, type = 1)
```

