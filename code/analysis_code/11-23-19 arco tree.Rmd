---
title: "11-7-19 tree"
author: "Megan Beaudry"
date: "11/7/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This code was developed after a lot of trial and error. _A. butzleri_ is our outcome variable, that was measured using qPCR data. However, this data was converted to positive and negative (based on the LOD). When intially testing this tree without converting the data, a tree was not produced. 

 

## R Markdown
Arco is the only yes no variable. Tune length is increased to 50. 
# LOAD LIBRARIES
```{r}
library('tidyr')
library('dplyr')
library('forcats')
library('ggplot2')
library('knitr')
library('caret')
library('doParallel')
library('rpart')
library('rpart.plot')
library('mda')
library('ranger')
library('e1071')
library('visdat')
```


# LOAD DATA
```{r}
clean_water_quality_data <- readRDS("../../data/processed_data/clean_water_quality_data.rds")
#if you get an error - this happens because you need to save the file first cause it refers to a relative path 
clean_data <- clean_water_quality_data
```

#
Change any characters to facotrs or numeric
and then drop levels at the end
If i cant change to factor or numeric drop them all together




# ORGANIZE DATA

Let's turn all variables into positive or negative, and see if we can predict _A. butzleri_. 
```{r}
#lets make a new object in case we mess something up
new_wq <- clean_water_quality_data


#convert characters to categorical varaibles
new_wq$Pond <- as.factor(as.character(new_wq$Pond))
new_wq$Sampling_Site <- as.factor(as.character(new_wq$Sampling_Site))
new_wq$Sampling_Site <- as.factor(as.character(new_wq$Sampling_Site))
str(new_wq)

#want to convert a new column with acro as yes or no to get the percent of the samples positive 
#lets do arco first
new_wq <- new_wq %>% mutate(arco_y_n= 
                      ifelse(A_butzleri_HSP60 < "3.391993", "negative",
                      ifelse(A_butzleri_HSP60 > "3.391994", "positive",
                      "no")))
clean_data_1 <- new_wq

```


MOVE
Move the outcome variable to the first row
```{r reorder}
#move A. butzleri to first row
clean_data_2 <- clean_data_1[, c(25, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24)]
clean_data_2 <- clean_data_2 %>% dplyr::select(-A_butzleri_HSP60)
```




SPLIT data
In order to deal with problems such as overfitting, we want to set aside some of the data at the start of the analysis. This helps use to evaluate our model. You do not want to evalute a model on the same data you use to train the model! The rule of thumb is to set aside 20-40% of your data for evaluation, so I decided to set aside 30% of my data for testing the model, and 70% to train the model. 
```{r split data}

library(caret)
library("tidyverse")
#this code does the data splitting. I still assume that your data is stored in the `d` object.
#uncomment to run
set.seed(123)
#extract observations/rows for training, assign to new variable. 
#Extracts 70% of the data into the trainset
trainset <- caret::createDataPartition(y = clean_data_2$arco_y_n, p = 0.7, list = FALSE)
#subsets out the dataset
data_train = clean_data_2[trainset,] 
#do the same for the test set
data_test = clean_data_2[-trainset,] 
```

PARALLELIZATION
We want to use mutliple processors, which the code below will allow us to do.

We want to use mutliple processors, which the code below will allow us to do.
```{r parallel}
n_cores <- 4 #number of cores to use
cl <- makePSOCKcluster(n_cores)
registerDoParallel(cl) #comment out this line if you don't want parallel computing
```

MODEL FITTING
Time to try to fit the model.

NULL MODEL
To define a null model, we need to determine what performance measure we want to track. We now have a categorical outcome 2 categories, so we could use a regular 2x2 table/confusion matrix. However, in class we used accuracy, which is the fraction of correct predictions. This is our baseline performance.


```{r null model}
mlr::measureACC("positive", data_train$arco_y_n)
```
SINGLE PREDICTOR MODEL
Lets start with a single predictor model. This means we are fitting the outcome (A. butlzeri) to each predictor one at a time. This allows us to get the an idea of the importance of the indivdual predictors.


```{r single predictor}


#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "arco_y_n"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train)[-1], ACC = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train)[n])) , data = data_train, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)

#In order to get this code to work i had to specify the carett:: package
```

#want accuracy to be around .7. We also find that this has a much higher accuracy that our null model!
```{r Arco full fit}
set.seed(1111)
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit2 = caret::train(arco_y_n  ~ ., data=data_train, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 10) 
print(fit2$results)
```


Tree
The tree is below. 

We see that the tree splits on first week 0, which makes sense as there should not be a starting concentration of A. butzleri in the stormwater ponds. It then splits on Enterococcus which is one of our FIB, rainfall, and another FIB (i.e., E. coli). This is logical as we would hope that FIB are doing their job and detecting the presence of pathogens. 

Similar to the first model we tried in class, we not that most of the variables are not part of the model. For this script, variable selection was done automatically (except for when we removed A_butzleri_HSP60, as that is the same data). 


```{r Final Tree}
arco_tree <- prp(fit2$finalModel, extra = 1, type = 1)
ww=17.8/2.54; wh=ww;
dev.print(device=png,width=ww,height=wh,units="in",res=600,file="../../results/arco_tree_21_1.png")
```



```{r}
# then drop all observations with missing values in both trian and test sets
data_test_remove <- drop_na(data_test)
data_train_remove <- drop_na(data_train)

mlr::measureACC("positive", data_train_remove$arco_y_n)
```




Tree try attempt #2
I want to try to make some adjustments to my tree to see if i can get more variables includes. Less start by removing the variable week, and see what that leaves us.
```{r redo beginning but rename data frame}
new_wq <- clean_water_quality_data
clean_data_3 <- new_wq %>% mutate(arco_y_n= 
                      ifelse(A_butzleri_HSP60 < "3.391993", "negative",
                      ifelse(A_butzleri_HSP60 > "3.391994", "positive",
                      "no")))
```


```{r remove week}
clean_data_3 <- clean_data_3[, c(25, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24)]
clean_data_3 <- clean_data_3 %>% dplyr::select(-A_butzleri_HSP60, -Week)
```
Now we need to split the data again.



```{r split tree #2}
library(caret)
library("tidyverse")
#this code does the data splitting. I still assume that your data is stored in the `d` object.
#uncomment to run
set.seed(123)
#extract observations/rows for training, assign to new variable. 
#Extracts 70% of the data into the trainset
trainset <- caret::createDataPartition(y = clean_data_3$arco_y_n, p = 0.7, list = FALSE)
#subsets out the dataset
data_train_3 = clean_data_3[trainset,] 
#do the same for the test set
data_test_3 = clean_data_3[-trainset,] 
```

```{r null model 2}
mlr::measureACC("positive", data_train_3$arco_y_n)
```
Interesting, by removing week our null model stayed the same. Let's move onto single predictor and see if that changes anything.

```{r single predictor tree 2}


#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "arco_y_n"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_3)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_3)[-1], ACC = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_3)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_3)[n])) , data = data_train_3, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)

#In order to get this code to work i had to specify the carett:: package
```
Okay so the accuracy stay in the same range....

```{r Arco full fit try 2}
set.seed(1111)
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit2 = caret::train(arco_y_n  ~ ., data=data_train_3, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 10) 
print(fit2$results)
```

```{r Final Tree 2}
arco_tree <- prp(fit2$finalModel, extra = 1, type = 1)
ww=17.8/2.54; wh=ww;
dev.print(device=png,width=ww,height=wh,units="in",res=600,file="../../results/arco_tree_21_2.png")
```
Well eliminating week did not do what I was hoping. I was hoping the tree would include more branches, but instead it has less! Ugh. Let's try increasing the tune length but keeping week. 


Tree attempt #3
Well that was not successful at all! Let's see what happens if i adjust the tune length. By increasing the tune length from 10 to 50 the algorithm should try more parameters.
new df - clean_data_4
```{r data set up steps 3}
new_wq <- clean_water_quality_data
clean_data_4 <- new_wq %>% mutate(arco_y_n= 
                      ifelse(A_butzleri_HSP60 < "3.391993", "negative",
                      ifelse(A_butzleri_HSP60 > "3.391994", "positive",
                      "no")))
clean_data_4 <- clean_data_4[, c(25, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24)]
clean_data_4 <- clean_data_4 %>% dplyr::select(-A_butzleri_HSP60, -Week)

```
split the data again.

```{r split tree #3}
library(caret)
library("tidyverse")
#this code does the data splitting. I still assume that your data is stored in the `d` object.
#uncomment to run
set.seed(123)
#extract observations/rows for training, assign to new variable. 
#Extracts 70% of the data into the trainset
trainset <- caret::createDataPartition(y = clean_data_4$arco_y_n, p = 0.7, list = FALSE)
#subsets out the dataset
data_train_4 = clean_data_4[trainset,] 
#do the same for the test set
data_test_4 = clean_data_4[-trainset,] 
```

```{r null model 3}
mlr::measureACC("positive", data_train_4$arco_y_n)
```
This should still be the same as the first tree, as we have not changed anything yet. Let's adjust the tune length to 50.  

```{r single predictor tree 3}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "arco_y_n"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_4)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_4)[-1], ACC = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_4)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_4)[n])) , data = data_train_4, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 50)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)

#In order to get this code to work i had to specify the carett:: package
```
Okay so the accuracy stay in the same range....lets adjust this tune length also to 50. 

```{r Arco full fit try 3}
set.seed(1111)
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit2 = caret::train(arco_y_n  ~ ., data=data_train_4, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 50) 
print(fit2$results)
```

```{r Final Tree 3}
arco_tree <- prp(fit2$finalModel, extra = 1, type = 1)
ww=17.8/2.54; wh=ww;
dev.print(device=png,width=ww,height=wh,units="in",res=600,file="../../results/arco_tree_21_3.png")
```
These trees are not looking like what I was expecting! I was really hoping that the predictors would be microbial source tracking markers, cause to me that makes the most biological sense! I am going to try to get rid of every variable that I believe does not make biological sense, and see what happens....

#Tree Attempt 4
Removing all not qPCR variables, and converting all qPCR variables to positive and negative. 
```{r data set up 4}
clean_water_quality_data <- readRDS("../../data/processed_data/clean_water_quality_data.rds")
new_wq <- clean_water_quality_data

new_wq <- new_wq %>% mutate(arco_y_n= 
                      ifelse(A_butzleri_HSP60 < "3.391993", "negative",
                      ifelse(A_butzleri_HSP60 > "3.391994", "positive",
                      "no")))

#Now HF183 and the rest
new_wq <- new_wq %>% mutate(HF183= 
                      ifelse(HF183 < "3.329601", "negative",
                      ifelse(HF183 > "3.329602", "positive",
                      "negative")))
new_wq <- new_wq %>% mutate(HumM2= 
                      ifelse(HumM2 < "3.847449", "negative",
                      ifelse(HumM2 > "3.847450", "positive",
                      "negative")))
new_wq <- new_wq %>% mutate(CG01= 
                      ifelse(CG01 < "3.108565", "negative",
                      ifelse(CG01 > "3.108566", "positive",
                      "negative")))
new_wq <- new_wq %>% mutate(LeeSg= 
                      ifelse(LeeSg < "3.283979", "negative",
                      ifelse(LeeSg > "3.283980", "positive",
                      "negative")))
new_wq <- new_wq %>% mutate(Dog3= 
                      ifelse(Dog3 < "3.156549", "negative",
                      ifelse(Dog3 > "3.156550", "positive",
                      "negative")))
new_wq <- new_wq %>% mutate(MuBac= 
                      ifelse(MuBac < "3.554852", "negative",
                      ifelse(MuBac > "3.554853", "positive",
                      "negative")))
new_wq <- new_wq %>% mutate(Rum2Bac= 
                      ifelse(Rum2Bac < "3.457125", "negative",
                      ifelse(Rum2Bac > "3.457126", "positive",
                      "negative")))
new_wq <- new_wq %>% mutate(Salmonella_spp_InvA= 
                      ifelse(Salmonella_spp_InvA < "3.170848", "negative",
                      ifelse(Salmonella_spp_InvA > "3.170849", "positive",
                      "negative")))
new_wq <- new_wq %>% mutate(Campylobacter_spp_Van_Dkye= 
                      ifelse(Campylobacter_spp_Van_Dkye < "3.554852", "negative",
                      ifelse(Campylobacter_spp_Van_Dkye > "3.554853", "positive",
                      "negative")))

#water quality indicators
new_wq <- new_wq %>% mutate(Enterococcus_CCE= 
                      ifelse(Enterococcus_CCE < "3.102", "negative",
                      ifelse(Enterococcus_CCE > "3.103", "positive",
                      "negative")))

new_wq <- new_wq %>% mutate(thermotolerant_coiforms= 
                      ifelse(thermotolerant_coliforms < "2.602", "negative",
                      ifelse(thermotolerant_coliforms > "2.603", "positive",
                      "negative")))
clean_data_5 <- new_wq
clean_data_5 <- clean_data_5[, c(25, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24)]
clean_data_5 <- clean_data_5 %>% dplyr::select(-A_butzleri_HSP60, -Week, -Sampling_Site, -Pond, -Date, -Date_Sampled, -Week)
```

split the data again.

```{r split tree #4}
library(caret)
library("tidyverse")
#this code does the data splitting. I still assume that your data is stored in the `d` object.
#uncomment to run
set.seed(123)
#extract observations/rows for training, assign to new variable. 
#Extracts 70% of the data into the trainset
trainset <- caret::createDataPartition(y = clean_data_5$arco_y_n, p = 0.7, list = FALSE)
#subsets out the dataset
data_train_5 = clean_data_5[trainset,] 
#do the same for the test set
data_test_5 = clean_data_5[-trainset,] 
```

```{r null model 4}
mlr::measureACC("positive", data_train_5$arco_y_n)
```
The ACC stays the same even though i removed a lot of variables. I'm going to keep the tune length at 50 like the last tree.

```{r single predictor tree 4}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "arco_y_n"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_5)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_5)[-1], ACC = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_5)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_5)[n])) , data = data_train_5, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 50)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)

#In order to get this code to work i had to specify the carett:: package
```
Okay so the accuracy stay in the same range....lets adjust this tune length also to 50. 



Welp. We just get a blob! Even with a tune length of 50. I guess that tells me that the microbial source tracking markers are not good predictors....This is not what i expected. Our tree left out the majority of predictors (19 of them!) as it did not find them useful. I was suprised by this, as I figured things such as human fecal material (i.e, HF183 or HumM2) would have been useful. 

As i already removed the variables that would compound our model, and increased the tune length in prior attempts at this script, we will move forward.


```{r null model 4}
mlr::measureACC("positive", data_train_5$arco_y_n)
```
The ACC stays the same even though i removed a lot of variables. I'm going to keep the tune length at 50 like the last tree.

```{r single predictor tree 4}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "arco_y_n"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_5)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_5)[-1], ACC = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_5)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_5)[n])) , data = data_train_5, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 50)
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)

#In order to get this code to work i had to specify the carett:: package
```
Okay so the accuracy stay in the same range....lets adjust this tune length also to 50. 

```{r Arco full fit try 4}
set.seed(1111)
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit2 = caret::train(arco_y_n  ~ ., data=data_train_5, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 50) 
print(fit2$results)
```

```{r Final Tree 4}
arco_tree <- prp(fit2$finalModel, extra = 1, type = 1)
ww=17.8/2.54; wh=ww;
dev.print(device=png,width=ww,height=wh,units="in",res=600,file="../../results/arco_tree_21_4.png")
```


# Evaluate our trees
I attempted to evuate my tree, just as we had done in class. Unfortunately I kept running into the error message I posted to the discussion board in class. I spent over 12 hours just trying different ways to fix the error message, and could not figure it out. I also asked a lab mate for help troubleshooting (as sometimes it helps to brainstorm with others!), and still no progress. I have # out the code below, as we do not want error messages. I have also provided a list of the things I tried: 
NA omits on all variables
Dropped -date,-date_sampled, -sample_ID (dropped them indivdually, dropped them in all combinations)
put week and pond as factor
changed rainfall as numeric 
STEC1 and STEC2 as factors
dropped STEC1 and STEC2 only
dropped week, pond, rainfall,
dropped everything that was not qPCR data
converted all qPCR data to positive and negative, and dropped the rest
Converted Enteroalert to numeric
dropped enteroaltert
Mutated STEC so NA was negative - still did not work
Took out week 
Used droplevels to drop all emptry factor levels from samples that for example had positives but were not positives
Took all factors outs and just left the numerics - still did not work
Blog post on stack overflows that zero values and numerics will come back as null - removed all zero values. Still did not work. 


```{r randomforest, echo=TRUE}
#data_train_remove <- data_train
#set.seed(1111) #makes each code block reproducible
#tuning_grid <- expand.grid( .mtry = seq(1,7,by=1), .splitrule = "gini", .min.node.size = seq(2,8,by=1) )
#fit2 = train(arco_y_n ~ ., data=data_train_remove, method="ranger",  trControl = fitControl, tuneGrid = tuning_grid, na.action = na.pass) 
#again had to specify caret for the package
#needed to change the data to data_train_remove or else got an error message
```

```{r gbm, echo=TRUE}
library('gbm')
#gbmGrid <- expand.grid(interaction.depth = seq(1, 7, by = 2), n.trees = 300, shrinkage = c(0.1, 0.01), n.minobsinnode = c(2,4,6))
#fit3 = caret::train(arco_y_n ~ ., data=data_train_remove, method="gbm", trControl = fitControl, verbose=FALSE, tuneGrid = gbmGrid) 
```


```{r stop parallel}
# shut down the parallel computing cluster we created at the beginning of the analysis
stopCluster(cl)
```